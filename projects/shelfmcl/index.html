<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> ShelfAware - Real-Time Semantic Localization in Quasi-Static Environments | Shivendra Agrawal </title> <meta name="author" content="Shivendra Agrawal"> <meta name="description" content="2024-2025 - In submission"> <meta name="keywords" content="HRI, Ph.D., Robotics, Assistive Technology, Machine Learning"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://shivendraagrawal.github.io/projects/shelfmcl/"> <script src="/assets/js/theme.js?26db7f3055421146867074eb189f4598"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Shivendra</span> Agrawal </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/resume/">CV </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/press/">Press Coverage </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/mentorship/">Mentorship </a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">Talks </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">ShelfAware - Real-Time Semantic Localization in Quasi-Static Environments</h1> <p class="post-description">2024-2025 - In submission</p> </header> <article> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Team members:
Shivendra Agrawal, Jake Brawer, Ashutosh Naik, Alessandro Roncone, Bradley Hayes
</code></pre></div></div> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">arXiv</abbr> </div> <div id="agrawal2025shelfaware" class="col-sm-8"> <div class="title">ShelfAware: Real-Time Semantic Localization in Quasi-Static Environments</div> <div class="author"> <em>Shivendra Agrawal</em>, Jake Brawer, <a href="https://ashutoshnaik.com/" rel="external nofollow noopener" target="_blank">Ashutosh Naik</a>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Alessandro Roncone, Bradley Hayes' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>arXiv preprint arXiv:2512.09065</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2512.09065" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">agrawal2025shelfaware</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ShelfAware: Real-Time Semantic Localization in Quasi-Static Environments}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Agrawal, Shivendra and Brawer, Jake and Naik, Ashutosh and Roncone, Alessandro and Hayes, Bradley}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2512.09065}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">topic</span> <span class="p">=</span> <span class="s">{shelfmcl}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2512.09065}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> <h2 id="abstract">Abstract</h2> <p>Localization in dynamic, visually aliased environments like grocery stores is a difficult challenge for autonomous systems. Aisles often look identical geometrically, and stock changes frequently. <strong>ShelfAware</strong> is a novel semantic localization framework that achieves robust, real-time global localization using only low-cost sensors—specifically, a monocular RGB-D camera on a smartphone. Unlike traditional methods that rely on expensive LiDAR or detailed geometric maps, ShelfAware uses a <strong>Semantic Particle Filter</strong>. It leverages Visual-Inertial Odometry (VIO) for motion estimation and corrects drift by matching detected product categories (e.g., “cereal”, “soda”) against a lightweight semantic map. This allows the system to localize accurately even in featureless or repetitive aisles.</p> <div class="row justify-content-center"> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper/shelfmcl/husky.gif" sizes="95vw"></source> <img src="/assets/img/paper/shelfmcl/husky.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Our system's capabilities across tasks" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="the-shelfaware-approach">The ShelfAware Approach</h2> <p>The core of our solution is a particle filter that fuses visual-inertial odometry with semantic observations.</p> <ol> <li> <strong>Semantic Mapping:</strong> We utilize a pre-built semantic map that stores the locations of product categories rather than individual items, making the map robust to daily stock changes.</li> <li> <strong>Observation Model:</strong> As the agent moves, a custom YOLO-based detector identifies product categories in the camera frame.</li> <li> <strong>Particle Update:</strong> We project these detections into 3D space. Particles that “expect” to see the detected products at their hypothesized location receive higher weights, while those that don’t are penalized. This effectively converges the particle cloud to the robot’s true location.</li> </ol> <div class="row justify-content-center"> <div class="col-sm-6 mt-3 mt-md-0 d-flex align-items-stretch" style="vertical-align:middle"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper/shelfmcl/sensors.png" sizes="95vw"></source> <img src="/assets/img/paper/shelfmcl/sensors.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Sensors Used in the System" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p><br></p> <p><strong>Modularity</strong></p> <ul> <li> <strong>Mountable on Carts/Strollers:</strong> Can add autonomous capabilities to existing equipment.</li> <li> <strong>Wearable:</strong> Can support assistive technology for navigation.</li> </ul> <div class="row justify-content-center"> <div class="col-sm-4 mt-3 mt-md-0 mx-3" style="vertical-align:middle"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper/shelfmcl/maria_cart.gif" sizes="95vw"></source> <img src="/assets/img/paper/shelfmcl/maria_cart.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Mountable Rig on a Cart" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0 mx-3" style="vertical-align:middle"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper/shelfmcl/dusty_wearable.gif" sizes="95vw"></source> <img src="/assets/img/paper/shelfmcl/dusty_wearable.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Wearable Rig for Assistive Technology" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p><br></p> <h2 id="algorithm">Algorithm</h2> <ul> <li> <h3 id="semantic-mapping">Semantic Mapping</h3> <p>We trained a custom classifier to classify products into a fixed number of classes.</p> </li> </ul> <div class="row justify-content-center"> <div class="col-sm-4 mt-3 mt-md-0 mx-3" style="vertical-align:middle"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper/shelfmcl/classification_rgb.gif" sizes="95vw"></source> <img src="/assets/img/paper/shelfmcl/classification_rgb.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Semantic Mapping - Classification" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0 mx-3" style="vertical-align:middle"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper/shelfmcl/classification_d.gif" sizes="95vw"></source> <img src="/assets/img/paper/shelfmcl/classification_d.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Semantic Mapping - Classification" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <h3 id="pose-correction">Pose Correction</h3> <p>Real-world pose estimates obtained through inverse camera projection are refined using ray casting on the semantic map.</p> </li> </ul> <div class="row justify-content-center align-items-center"> <div class="col-sm-4 mt-3 mt-md-0" style="vertical-align:middle"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper/shelfmcl/raycast.gif" sizes="95vw"></source> <img src="/assets/img/paper/shelfmcl/raycast.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Product Clusters After Pose Correction" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-1 text-center" style="font-size: 2em;"> <i class="fas fa-arrow-right"></i> </div> <div class="col-sm-4 mt-3 mt-md-0" style="vertical-align:middle"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper/shelfmcl/shelfaware_product_map.png" sizes="95vw"></source> <img src="/assets/img/paper/shelfmcl/shelfaware_product_map.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="ShelfAware Product Map" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p><br></p> <ul> <li> <h3 id="semantic-localization">Semantic Localization</h3> <p>Semantic information is fused with the depth observation to in a Monte Carlo Localization framework.</p> </li> </ul> <div class="row justify-content-center"> <div class="col-sm-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper/shelfmcl/overview_v3.png" sizes="95vw"></source> <img src="/assets/img/paper/shelfmcl/overview_v3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="System Architecture" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p><br></p> <h2 id="demo">Demo</h2> <div class="video-container"> <iframe src="https://www.youtube.com/embed/8q65wmsDsjU?si=5Ti_ab-E149Cmji4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> </div> <p><br></p> <h2 id="experimental-results">Experimental Results</h2> <p>We evaluated ShelfAware in a semantically dense retail environment (a mock store) across diverse conditions, including cart-mounted and wearable setups. The system achieved a <strong>96%</strong> global localization success rate with a mean time-to-convergence of <strong>1.91s</strong>, significantly outperforming geometric baselines like MCL (<strong>22%</strong> success) and AMCL (<strong>10%</strong> success). The system operates in real-time (<strong>9.6Hz</strong>) on consumer laptop-class hardware, demonstrating robust tracking even in dynamic, visually aliased aisles.</p> <div class="row justify-content-center"> <div class="col-sm-10 mt-3 mt-md-0 mx-3" style="vertical-align:middle"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper/shelfmcl/sample_trajectories.png" sizes="95vw"></source> <img src="/assets/img/paper/shelfmcl/sample_trajectories.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Sample Trajectories" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Ground truth trajectories shown in blue and trajectories predicted by ShelfAware shown in red. </div> <p><br></p> <div class="publications"> </div> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@article</span><span class="p">{</span><span class="nl">agrawal2025shelfaware</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{ShelfAware: Real-Time Visual-Inertial Semantic Localization in Quasi-Static Environments with Low-Cost Sensors}</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Agrawal, Shivendra and Brawer, Jake and Naik, Ashutosh and Roncone, Alessandro and Hayes, Bradley}</span><span class="p">,</span>
  <span class="na">journal</span><span class="p">=</span><span class="s">{arXiv preprint arXiv:2512.09065}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="s">{2025}</span>
<span class="p">}</span>
</code></pre></div></div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Shivendra Agrawal. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Last updated: January 02, 2026. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-FHFY0JWTYK"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-FHFY0JWTYK");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-cv",title:"CV",description:"",section:"Navigation",handler:()=>{window.location.href="/resume/"}},{id:"nav-projects",title:"Projects",description:"",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-publications",title:"Publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-press-coverage",title:"Press Coverage",description:"",section:"Navigation",handler:()=>{window.location.href="/press/"}},{id:"nav-teaching",title:"Teaching",description:"",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"nav-mentorship",title:"Mentorship",description:"",section:"Navigation",handler:()=>{window.location.href="/mentorship/"}},{id:"nav-talks",title:"Talks",description:"",section:"Navigation",handler:()=>{window.location.href="/talks/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"news-awarded-the-david-t-spalding-graduate-teaching-award",title:"Awarded the David T. Spalding Graduate Teaching Award.",description:"",section:"News"},{id:"news-recieved-an-award-for-our-poster-at-the-annual-research-expo-22-for-our-work",title:"Recieved an award for our poster at the Annual Research Expo 22 for...",description:"",section:"News"},{id:"news-demoed-our-work-at-the-amazon-re-mars-2022",title:"Demoed our work. at the Amazon re:MARS 2022.",description:"",section:"News"},{id:"news-presented-our-paper-on-faciliating-navigation-and-social-norm-adherence-for-the-bvi-at-iros-2022-kyoto",title:"Presented our paper on faciliating navigation and social norm adherence for the BVI...",description:"",section:"News"},{id:"news-presented-our-workshop-paper-on-our-new-system-called-shelfhelp-an-independent-grocery-shopping-assitant-for-the-bvi-at-iros-2022",title:"Presented our workshop paper on our new system called ShelfHelp: An independent grocery...",description:"",section:"News"},{id:"news-our-work-on-assiting-visually-impaired-people-to-perform-independent-grocery-shopping-got-accepted-for-aamas-2023-london",title:"Our work on assiting visually impaired people to perform independent grocery shopping got...",description:"",section:"News"},{id:"news-our-work-on-assisting-visually-impaired-people-to-perform-independent-grocery-shopping-was-a-winner-at-cu-boulder-s-annual-research-expo",title:"Our work on assisting visually impaired people to perform independent grocery shopping was...",description:"",section:"News"},{id:"news-awarded-the-aamas-student-scholarship-2023",title:"Awarded the AAMAS Student Scholarship 2023",description:"",section:"News"},{id:"news-represented-cu-robotics-research-at-leading-with-impact-event-in-denver-and-presented-our-work",title:"Represented CU Robotics research at Leading with Impact event in Denver and presented...",description:"",section:"News"},{id:"news-was-the-social-media-chair-for-the-human-robot-interaction-conference-2024-boulder-co",title:"Was the social media chair for the Human-Robot Interaction Conference 2024, Boulder, CO...",description:"",section:"News"},{id:"projects-an-arkit-app-to-help-people-with-learning-disabilities",title:"An ARKit app to help people with learning disabilities",description:"CSCI-5413 Augmented Reality Project using ARKit",section:"Projects",handler:()=>{window.location.href="/projects/textAR/"}},{id:"projects-robot-guide-dog-for-visually-impaired",title:"Robot guide dog for visually impaired",description:"Algorithmic Human-Robot Interaction class project Spring 2019",section:"Projects",handler:()=>{window.location.href="/projects/guide_dog/"}},{id:"projects-an-explainable-reinforcement-learning-approach-for-enabling-robots-to-coach-humans",title:"An Explainable Reinforcement Learning Approach for Enabling Robots to Coach Humans",description:"Best Technical Paper Runner-up @ Human-Robot Interaction conference 2019",section:"Projects",handler:()=>{window.location.href="/projects/explainable_ai/"}},{id:"projects-smart-cane-to-find-socially-preferred-seats",title:"Smart cane to find socially preferred seats",description:"2021-2022 - Published paper at IROS 2022",section:"Projects",handler:()=>{window.location.href="/projects/social_guidance/"}},{id:"projects-shelfhelp-an-assitive-robotic-system-to-support-grocery-shopping-for-bvi",title:"ShelfHelp - An assitive robotic system to support grocery shopping for BVI",description:"2023 - Published paper at AAMAS 23",section:"Projects",handler:()=>{window.location.href="/projects/shelfhelp/"}},{id:"projects-autonomous-anomaly-detection-and-explanation",title:"Autonomous Anomaly Detection and Explanation",description:"2024 - work done with NEC corporation",section:"Projects",handler:()=>{window.location.href="/projects/anomaly/"}},{id:"projects-shelfaware-real-time-semantic-localization-in-quasi-static-environments",title:"ShelfAware - Real-Time Semantic Localization in Quasi-Static Environments",description:"2024-2025 - In submission",section:"Projects",handler:()=>{window.location.href="/projects/shelfmcl/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%73%68%69%76%65%6E%64%72%61.%61%67%72%61%77%61%6C@%63%6F%6C%6F%72%61%64%6F.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=6UGhqKsAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/ShivendraAgrawal","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/shivendraiitkgp","_blank")}},{id:"socials-stackoverflow",title:"Stackoverflow",section:"Socials",handler:()=>{window.open("https://stackoverflow.com/users/1641628","_blank")}},{id:"socials-youtube",title:"YouTube",section:"Socials",handler:()=>{window.open("https://youtube.com/@shivendraiitkgp","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>